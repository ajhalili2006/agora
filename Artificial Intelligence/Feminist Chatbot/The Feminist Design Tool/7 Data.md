# 7 Data
There are two main areas where data might be problematic.

1. Training data for machine learning having its own inherent bias based on how it's chosen
2. The collection of data ommitting questions or responses relevant to demographics outside the mainstream

## Questions to ask yourself

1. How will you collect and treat data through the development of your design? 
2. Are you aware of how bias might manifest itself in your training data? 
3. Are you aware of how bias might manifest itself in the AI techniques that power your design (like machine learning)? 
4. How could stakeholder-generated data and feedback be used to improve the design?
5. Will the design learn from the stakeholderâ€™s behaviour, and if so, are you assuming that the design will get it right? 
6. What mechanisms or features could make these assumptions visible to the stakeholder and empower them to change the assumptions if they want to?
7. How will you protect stakeholder data?

Go to [[8 Architecture]]

For the full list see [[The Feminist Design Tool]]

This is part of the [[Feminist Chatbot Main Page]]